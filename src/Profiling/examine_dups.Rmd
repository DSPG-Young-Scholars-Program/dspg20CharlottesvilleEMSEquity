---
title: "Untitled"
output: html_document
---

```{r}
library(glue)
library(tidyr)
library(ggridges)
library(ggplot2)

source(here::here("src","Profiling","joining_albemarle_charlottesville.R"))
```

```{r}
charlottesville %>% 
  mutate(total_na = rowSums(is.na(.))) %>%
  select(total_na, everything()) %>% 
  # filter(response_incident_number == "2017-00002675")
  group_by(response_incident_number) %>% 
  count(sort = TRUE) %>% 
  group_by(n) %>% 
  count()

charlottesville %>% 
  group_by(response_incident_number) %>% 
  mutate(num_dups = n()) %>% 
  filter(num_dups == 2)
```

Things that appear to split a set:
  - conflicting situation_provider_secondary_impression_description_and_code (could likely turn into a list column)
  - one row is missing data another has
  - conflicting vitals_level_of_responsiveness_avpu
  - One row from albemarle, one from charlottesville
  
Going forward, I'm going to consider a unique observation to be a (response_incident_number, response_ems_unit_call_sign) pair
  
Lets get a more formal look at where the mismatches are:

```{r}
to_drop <- c("patient_medical_history_obtained_from_list", 
             "patient_advance_directives_list",
             "cardiac_arrest_witnessed_by_list",
             "injury_cause_of_injury",
             "outcome_external_report_type",
             "outcome_external_report_number",
             "cardiac_arrest_initial_cpr_date_time",
             "cardiac_arrest_who_initiated_cpr_with_code",
             "medication_given_description_and_rxcui_code",
             "patient_medication_given_descriptions_list",
             "cardiac_arrest_rosc_date_time",
             "destination_cardiac_arrest_team_activation_date_time",
             "patient_weight_actual_or_estimate_pounds",
             "injury_mechanism_of_injury_list",
             "cad_crew_member_full_name_and_level_list",
             "patient_suspected_influenza_type_illness",
             "patient_mental_status_assessment_exam_details",
             "patient_neurological_assessment_exam_details",
             "patient_skin_assessment_exam_details",
             "patient_head_assessment_exam_details",
             "patient_respiratory_effort_list",
             "vitals_cardiac_rhythm_ecg_findings_list")

unique_elements <- charlottesville %>% 
  select(-to_drop) %>% 
  filter(response_incident_number != "0") %>% # an error response incident number
  group_by(response_incident_number, response_ems_unit_call_sign) %>% 
  mutate(total_dups = n()) %>%
  filter(total_dups > 1) %>% 
  summarise(across(everything(), ~length(unique(.x[!is.na(.x)]))))
```

This figure shows which variables with duplicated rows have more than one unique element in each column. It has been scaled to exagerrate the effect. The variables with peaks at 2 or greater are problem variables, meaning many of them have data that conflict with eachother. Examples of this include vitals_level_of_responsivness_avpu, which can read someone is alert for one duplicate and unresponsive for the other. 
```{r, fig.height = 10}
unique_elements %>% 
  ungroup() %>% 
  pivot_longer(cols = 3:61) %>% 
  mutate(total_dups = 1/total_dups, value = total_dups * value) %>% 
  ggplot(aes(x = value, y = name)) +
  geom_density_ridges(panel_scaling = FALSE, scale = 5) +
  theme_minimal() +
  coord_cartesian(xlim= c(1.8, 13))
```

Biggest problems vars:
- vitals_level_of_responsiveness_avpu
- situation_provider_secondary_impression_description_and_code

Smaller problem vars:
- situation_complaint_duration
- situation_complaint_duration_time_units
- patient_age
- patient_age_range
- situation_provider_primary_impression_code_and_description
- situation_primary_complaint_statement_list
- vitals_cardiac_rhythm_ecg_findings_list


Do some duplicate removal

Start by removing full duplicates and filling NAs within observations with other data from them. 
```{r}
charlottesville <- as_tibble(charlottesville) # coerce into a tibble

fill_step <- charlottesville %>% 
  select(-to_drop) %>% 
  filter(!duplicated(.)) %>%  # remove 6868 full duplicates sum(dulplicated(select(charlottesvill, -to_drop)))
  filter(response_incident_number != "0") %>%  # remove bogus response incident number
  select(response_incident_number, response_ems_unit_call_sign, everything()) %>% 
  group_by(response_incident_number, response_ems_unit_call_sign) %>% 
  fill(3:ncol(.), .direction = "updown")

fill_deduped <- fill_step %>% 
  ungroup() %>% 
  filter(!duplicated(.)) # gets rid of an additional 1054 duplicate rows sum(duplicated(fill_step))

# we want there to be only 36692 rows, still have ~6000 too many
# charlottesville %>% 
#   filter(response_incident_number != "0") %>% 
#   count(response_incident_number, response_ems_unit_call_sign) %>% 
#   nrow()
```


Now I'm going to turn situation_provider_secondary_impression_description_and_code into a list column. 

```{r}
combine_secondary <- fill_deduped %>% 
  group_by(response_incident_number, response_ems_unit_call_sign) %>% 
  mutate(situation_provider_secondary_impression_description_and_code = list(unique(situation_provider_secondary_impression_description_and_code))) %>% 
  ungroup() %>% 
  filter(!duplicated(.))

# down to 39023 rows, making progress!
# nrow(combine_secondary)
```

I'm going to try and remove vitals_level_of_responsiveness_avpu to see if that improves things (probably can't use it since its so messed up)

```{r}
removed_responsiveness <- combine_secondary %>% 
  select(-vitals_level_of_responsiveness_avpu) %>% 
  filter(!duplicated(.))

# This removes another 1000 rows, down to 38075
# nrow(removed_responsivness)
```

Time to see whats going on with the age columns. 

```{r}
removed_responsiveness %>% 
  group_by(response_incident_number, response_ems_unit_call_sign) %>% 
  filter(n() > 1)
```

